{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-10T19:33:55.580305195Z",
     "start_time": "2023-09-10T19:33:38.526432196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 44082 samples\n"
     ]
    }
   ],
   "source": [
    "from llvm_ml.data import load_pyg_dataset\n",
    "banned_ids = []\n",
    "dataset = load_pyg_dataset(\"./data/ryzen3600_v11.cbuf\", use_binary_opcode=False, banned_ids=banned_ids)\n",
    "print(f\"Training with {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                                    | Type                   | Params\n",
      "------------------------------------------------------------------------------------\n",
      "0  | embedding                               | MCEmbedding            | 5.4 M \n",
      "1  | embedding.embedding                     | Embedding              | 5.4 M \n",
      "2  | embedding.pos_encoding                  | PositionalEncoding     | 0     \n",
      "3  | embedding.norm                          | LayerNorm              | 512   \n",
      "4  | encoder                                 | MCEncoder              | 660 K \n",
      "5  | encoder.attention                       | MCAttention            | 528 K \n",
      "6  | encoder.attention.attention             | GATConvJittable_0ad365 | 265 K \n",
      "7  | encoder.attention.attention.aggr_module | SumAggregation         | 0     \n",
      "8  | encoder.attention.attention.lin_src     | Linear                 | 262 K \n",
      "9  | encoder.attention.linear                | Linear                 | 262 K \n",
      "10 | encoder.attention.norm                  | LayerNorm              | 512   \n",
      "11 | encoder.feed_forward                    | Sequential             | 131 K \n",
      "12 | encoder.feed_forward.0                  | Linear                 | 65.8 K\n",
      "13 | encoder.feed_forward.1                  | Dropout                | 0     \n",
      "14 | encoder.feed_forward.2                  | GELU                   | 0     \n",
      "15 | encoder.feed_forward.3                  | Linear                 | 65.8 K\n",
      "16 | encoder.feed_forward.4                  | Dropout                | 0     \n",
      "17 | encoder.norm                            | LayerNorm              | 512   \n",
      "18 | token_prediction                        | Linear                 | 5.4 M \n",
      "19 | softmax                                 | LogSoftmax             | 0     \n",
      "20 | regression                              | Linear                 | 257   \n",
      "21 | train_mae                               | MeanAbsoluteError      | 0     \n",
      "22 | val_mae                                 | MeanAbsoluteError      | 0     \n",
      "------------------------------------------------------------------------------------\n",
      "11.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 M    Total params\n",
      "45.736    Total estimated model params size (MB)\n",
      "2023-09-10 22:34:22.658009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-10 22:34:23.159034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4dd89511a3d404ca58366e3d20b3fcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e035a3274a714fb69291a53fd47a844c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CompilationError",
     "evalue": "at 34:12:\ndef triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n    xnumel = 20040\n    rnumel = 256\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rbase = tl.arange(0, RBLOCK)[None, :]\n    x1 = (xindex // 4)\n    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n    x0 = xindex % 4\n    tmp2 = tl.load(in_ptr2 + (x1), xmask)\n    _tmp5 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0\n    x3 = xindex\n    tmp6 = tl.load(in_ptr4 + (x3), xmask)\n    tmp7 = tl.load(in_ptr5 + (x1), xmask)\n    for roffset in range(0, rnumel, RBLOCK):\n        rindex = roffset + rbase\n        rmask = rindex < rnumel\n        r2 = rindex\n        tmp1 = tl.load(in_ptr1 + (r2 + (256*x0) + (1024*tmp0)), rmask & xmask, eviction_policy='evict_last', other=0)\n        tmp3 = tl.load(in_ptr3 + (r2 + (256*x0) + (1024*tmp2)), rmask & xmask, eviction_policy='evict_last', other=0)\n        tmp4 = tmp1 * tmp3\n        _tmp5 = tl.where(rmask & xmask, _tmp5 + tmp4, _tmp5)\n        tmp8 = tl.load(in_ptr6 + (x0 + (4*tmp7)), xmask)\n        tmp9 = 1e-16\n        tmp10 = tmp8 + tmp9\n        tmp11 = tmp6 / tmp10\n        tmp12 = tmp1 * tmp11\n        tl.atomic_add(out_ptr1 + (r2 + (256*x0) + (1024*tmp2) + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp12, rmask & xmask)\n    tmp5 = tl.sum(_tmp5, 1)[:, None]\n    tl.store(out_ptr0 + x3, tmp5, xmask)\n    tmp13 = -tmp5\n    tmp14 = 1e-16\n    tmp15 = tmp8 + tmp14\n            ^",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 937, in build_triton_ir\n    generator.visit(fn.parse())\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 855, in visit\n    return super().visit(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 183, in visit_Module\n    ast.NodeVisitor.generic_visit(self, node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 855, in visit\n    return super().visit(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 252, in visit_FunctionDef\n    has_ret = self.visit_compound_statement(node.body)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 177, in visit_compound_statement\n    self.last_ret_type = self.visit(stmt)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 855, in visit\n    return super().visit(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 301, in visit_Assign\n    values = self.visit(node.value)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 855, in visit\n    return super().visit(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 338, in visit_BinOp\n    lhs = self.visit(node.left)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 855, in visit\n    return super().visit(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 325, in visit_Name\n    return self.get_value(node.id)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 156, in get_value\n    raise ValueError(f'{name} is not defined')\nValueError: tmp8 is not defined\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/codecache.py\", line 549, in _worker_compile\n    kernel.precompile(warm_cache_only_with_cc=cc)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py\", line 69, in precompile\n    self.launchers = [\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py\", line 70, in <listcomp>\n    self._precompile_config(c, warm_cache_only_with_cc)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py\", line 83, in _precompile_config\n    triton.compile(\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 1620, in compile\n    next_module = compile(module)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 1549, in <lambda>\n    lambda src: ast_to_ttir(src, signature, configs[0], constants)),\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 962, in ast_to_ttir\n    mod, _ = build_triton_ir(fn, signature, specialization, constants)\n  File \"/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/triton/compiler.py\", line 942, in build_triton_ir\n    raise CompilationError(fn.src, node) from e\ntriton.compiler.CompilationError: at 34:12:\ndef triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n    xnumel = 20040\n    rnumel = 256\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rbase = tl.arange(0, RBLOCK)[None, :]\n    x1 = (xindex // 4)\n    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n    x0 = xindex % 4\n    tmp2 = tl.load(in_ptr2 + (x1), xmask)\n    _tmp5 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0\n    x3 = xindex\n    tmp6 = tl.load(in_ptr4 + (x3), xmask)\n    tmp7 = tl.load(in_ptr5 + (x1), xmask)\n    for roffset in range(0, rnumel, RBLOCK):\n        rindex = roffset + rbase\n        rmask = rindex < rnumel\n        r2 = rindex\n        tmp1 = tl.load(in_ptr1 + (r2 + (256*x0) + (1024*tmp0)), rmask & xmask, eviction_policy='evict_last', other=0)\n        tmp3 = tl.load(in_ptr3 + (r2 + (256*x0) + (1024*tmp2)), rmask & xmask, eviction_policy='evict_last', other=0)\n        tmp4 = tmp1 * tmp3\n        _tmp5 = tl.where(rmask & xmask, _tmp5 + tmp4, _tmp5)\n        tmp8 = tl.load(in_ptr6 + (x0 + (4*tmp7)), xmask)\n        tmp9 = 1e-16\n        tmp10 = tmp8 + tmp9\n        tmp11 = tmp6 / tmp10\n        tmp12 = tmp1 * tmp11\n        tl.atomic_add(out_ptr1 + (r2 + (256*x0) + (1024*tmp2) + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp12, rmask & xmask)\n    tmp5 = tl.sum(_tmp5, 1)[:, None]\n    tl.store(out_ptr0 + x3, tmp5, xmask)\n    tmp13 = -tmp5\n    tmp14 = 1e-16\n    tmp15 = tmp8 + tmp14\n            ^\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mCompilationError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 33\u001B[0m\n\u001B[1;32m     31\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog_graph(model)\n\u001B[1;32m     32\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m, logger\u001B[38;5;241m=\u001B[39mlogger, callbacks\u001B[38;5;241m=\u001B[39m[ModelSummary(max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)])\n\u001B[0;32m---> 33\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:520\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    518\u001B[0m model \u001B[38;5;241m=\u001B[39m _maybe_unwrap_optimized(model)\n\u001B[1;32m    519\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 520\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:559\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mattach_data(\n\u001B[1;32m    550\u001B[0m     model, train_dataloaders\u001B[38;5;241m=\u001B[39mtrain_dataloaders, val_dataloaders\u001B[38;5;241m=\u001B[39mval_dataloaders, datamodule\u001B[38;5;241m=\u001B[39mdatamodule\n\u001B[1;32m    551\u001B[0m )\n\u001B[1;32m    553\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    555\u001B[0m     ckpt_path,\n\u001B[1;32m    556\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    557\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    558\u001B[0m )\n\u001B[0;32m--> 559\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:935\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    932\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    934\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 935\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    938\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    939\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    940\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:978\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    976\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m--> 978\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    979\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:201\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start()\n\u001B[0;32m--> 201\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:354\u001B[0m, in \u001B[0;36m_FitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher\u001B[38;5;241m.\u001B[39msetup(combined_loader)\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 354\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:133\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.run\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 133\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:218\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mautomatic_optimization:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001B[39;00m\n\u001B[0;32m--> 218\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautomatic_optimization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    220\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmanual_optimization\u001B[38;5;241m.\u001B[39mrun(kwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:185\u001B[0m, in \u001B[0;36m_AutomaticOptimization.run\u001B[0;34m(self, optimizer, kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m         closure()\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch_idx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m result \u001B[38;5;241m=\u001B[39m closure\u001B[38;5;241m.\u001B[39mconsume_result()\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:261\u001B[0m, in \u001B[0;36m_AutomaticOptimization._optimizer_step\u001B[0;34m(self, batch_idx, train_step_and_backward_closure)\u001B[0m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_ready()\n\u001B[1;32m    260\u001B[0m \u001B[38;5;66;03m# model hook\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_module_hook\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moptimizer_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_step_and_backward_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_accumulate:\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_completed()\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:142\u001B[0m, in \u001B[0;36m_call_lightning_module_hook\u001B[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 142\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    145\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1265\u001B[0m, in \u001B[0;36mLightningModule.optimizer_step\u001B[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimizer_step\u001B[39m(\n\u001B[1;32m   1227\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1228\u001B[0m     epoch: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1231\u001B[0m     optimizer_closure: Optional[Callable[[], Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1232\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1233\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1234\u001B[0m \u001B[38;5;124;03m    Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001B[39;00m\n\u001B[1;32m   1235\u001B[0m \u001B[38;5;124;03m    the optimizer.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1263\u001B[0m \u001B[38;5;124;03m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001B[39;00m\n\u001B[1;32m   1264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1265\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_closure\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:158\u001B[0m, in \u001B[0;36mLightningOptimizer.step\u001B[0;34m(self, closure, **kwargs)\u001B[0m\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 158\u001B[0m step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_after_step()\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:224\u001B[0m, in \u001B[0;36mStrategy.optimizer_step\u001B[0;34m(self, optimizer, closure, model, **kwargs)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001B[39;00m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, pl\u001B[38;5;241m.\u001B[39mLightningModule)\n\u001B[0;32m--> 224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:114\u001B[0m, in \u001B[0;36mPrecisionPlugin.optimizer_step\u001B[0;34m(self, optimizer, model, closure, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001B[39;00m\n\u001B[1;32m    113\u001B[0m closure \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_closure, model, optimizer, closure)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:69\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     68\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/optim/adam.py:121\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[0;32m--> 121\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    124\u001B[0m     params_with_grad \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:101\u001B[0m, in \u001B[0;36mPrecisionPlugin._wrap_closure\u001B[0;34m(self, model, optimizer, closure)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_closure\u001B[39m(\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     91\u001B[0m     model: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.LightningModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     92\u001B[0m     optimizer: Optimizer,\n\u001B[1;32m     93\u001B[0m     closure: Callable[[], Any],\n\u001B[1;32m     94\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m     95\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 101\u001B[0m     closure_result \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_after_closure(model, optimizer)\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m closure_result\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001B[0m, in \u001B[0;36mClosure.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Tensor]:\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\u001B[38;5;241m.\u001B[39mloss\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:135\u001B[0m, in \u001B[0;36mClosure.closure\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_zero_grad_fn()\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m step_output\u001B[38;5;241m.\u001B[39mclosure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py:233\u001B[0m, in \u001B[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001B[0;34m(loss)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward_fn\u001B[39m(loss: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 233\u001B[0m     \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbackward\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:288\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 288\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    291\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:199\u001B[0m, in \u001B[0;36mStrategy.backward\u001B[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    197\u001B[0m closure_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpre_backward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module)\n\u001B[0;32m--> 199\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m closure_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mpost_backward(closure_loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module)\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_backward(closure_loss)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:67\u001B[0m, in \u001B[0;36mPrecisionPlugin.backward\u001B[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     51\u001B[0m     tensor: Tensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     56\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     57\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \n\u001B[1;32m     59\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m        \\**kwargs: Keyword arguments for the same purpose as ``*args``.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 67\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1054\u001B[0m, in \u001B[0;36mLightningModule.backward\u001B[0;34m(self, loss, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fabric\u001B[38;5;241m.\u001B[39mbackward(loss, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1053\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1054\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/autograd/function.py:274\u001B[0m, in \u001B[0;36mBackwardCFunction.apply\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImplementing both \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbackward\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvjp\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for a custom \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    271\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFunction is not allowed. You should only implement one \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    272\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof them.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    273\u001B[0m user_fn \u001B[38;5;241m=\u001B[39m vjp_fn \u001B[38;5;28;01mif\u001B[39;00m vjp_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Function\u001B[38;5;241m.\u001B[39mvjp \u001B[38;5;28;01melse\u001B[39;00m backward_fn\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43muser_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2365\u001B[0m, in \u001B[0;36maot_dispatch_autograd.<locals>.CompiledFunction.backward\u001B[0;34m(ctx, *flat_args)\u001B[0m\n\u001B[1;32m   2363\u001B[0m     out \u001B[38;5;241m=\u001B[39m CompiledFunctionBackward\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;241m*\u001B[39mall_args)\n\u001B[1;32m   2364\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2365\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcall_compiled_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2366\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2336\u001B[0m, in \u001B[0;36maot_dispatch_autograd.<locals>.CompiledFunction.backward.<locals>.call_compiled_backward\u001B[0;34m()\u001B[0m\n\u001B[1;32m   2334\u001B[0m     context \u001B[38;5;241m=\u001B[39m disable_autocast_manager \u001B[38;5;28;01mif\u001B[39;00m disable_amp \u001B[38;5;28;01melse\u001B[39;00m nullcontext\n\u001B[1;32m   2335\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m context(), track_graph_compiling(aot_config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackward\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 2336\u001B[0m         CompiledFunction\u001B[38;5;241m.\u001B[39mcompiled_bw \u001B[38;5;241m=\u001B[39m \u001B[43maot_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbw_compiler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2337\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbw_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_args\u001B[49m\n\u001B[1;32m   2338\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2340\u001B[0m ctx\u001B[38;5;241m.\u001B[39mmaybe_clear_saved_tensors()\n\u001B[1;32m   2341\u001B[0m out \u001B[38;5;241m=\u001B[39m call_func_with_args(\n\u001B[1;32m   2342\u001B[0m     CompiledFunction\u001B[38;5;241m.\u001B[39mcompiled_bw,\n\u001B[1;32m   2343\u001B[0m     all_args,\n\u001B[1;32m   2344\u001B[0m     steal_args\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   2345\u001B[0m     disable_amp\u001B[38;5;241m=\u001B[39mdisable_amp,\n\u001B[1;32m   2346\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_dynamo/backends/common.py:38\u001B[0m, in \u001B[0;36maot_autograd.<locals>.compiler_fn.<locals>._wrapped_bw_compiler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrapped_bw_compiler\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;66;03m# stop TorchDynamo from trying to compile our generated backwards pass\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m eval_frame\u001B[38;5;241m.\u001B[39mdisable(\u001B[43meval_frame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbw_compiler\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:209\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m dynamic_ctx\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__enter__\u001B[39m()\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 209\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    211\u001B[0m     set_eval_frame(prior)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m     compilation_metrics[key] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    162\u001B[0m t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 163\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:441\u001B[0m, in \u001B[0;36mcompile_fx.<locals>.bw_compiler\u001B[0;34m(model, example_inputs)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;129m@dynamo_utils\u001B[39m\u001B[38;5;241m.\u001B[39mdynamo_timed\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbw_compiler\u001B[39m(model: torch\u001B[38;5;241m.\u001B[39mfx\u001B[38;5;241m.\u001B[39mGraphModule, example_inputs):\n\u001B[1;32m    440\u001B[0m     fixed \u001B[38;5;241m=\u001B[39m count_tangents(model)\n\u001B[0;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_fixed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcudagraphs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcudagraphs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_backward\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgraph_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:595\u001B[0m, in \u001B[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001B[0;34m(gm, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m     compiled_fn\u001B[38;5;241m.\u001B[39m_boxed_call \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 595\u001B[0m     compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compiled_fn\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/debug.py:239\u001B[0m, in \u001B[0;36mDebugContext.wrap.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fn)\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m DebugContext():\n\u001B[0;32m--> 239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/contextlib.py:79\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 79\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:177\u001B[0m, in \u001B[0;36mcompile_fx_inner\u001B[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id)\u001B[0m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m V\u001B[38;5;241m.\u001B[39mset_graph_handler(graph):\n\u001B[1;32m    176\u001B[0m         graph\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;241m*\u001B[39mexample_inputs)\n\u001B[0;32m--> 177\u001B[0m         compiled_fn \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_to_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cudagraphs:\n\u001B[1;32m    180\u001B[0m     complex_memory_overlap_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m    181\u001B[0m         complex_memory_overlap(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m example_inputs\n\u001B[1;32m    182\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/graph.py:586\u001B[0m, in \u001B[0;36mGraphLowering.compile_to_fn\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompile_to_fn\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 586\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_to_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcall\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001B[0m, in \u001B[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    161\u001B[0m     compilation_metrics[key] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    162\u001B[0m t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 163\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m time_spent \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/graph.py:575\u001B[0m, in \u001B[0;36mGraphLowering.compile_to_module\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mdebug:\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;28mprint\u001B[39m(code)\n\u001B[0;32m--> 575\u001B[0m mod \u001B[38;5;241m=\u001B[39m \u001B[43mPyCodeCache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconstants\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    577\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(mod, name, value)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/codecache.py:528\u001B[0m, in \u001B[0;36mPyCodeCache.load\u001B[0;34m(cls, source_code)\u001B[0m\n\u001B[1;32m    526\u001B[0m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__file__\u001B[39m \u001B[38;5;241m=\u001B[39m path\n\u001B[1;32m    527\u001B[0m mod\u001B[38;5;241m.\u001B[39mkey \u001B[38;5;241m=\u001B[39m key\n\u001B[0;32m--> 528\u001B[0m \u001B[43mexec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__dict__\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__dict__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[38;5;66;03m# another thread might set this first\u001B[39;00m\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mcache\u001B[38;5;241m.\u001B[39msetdefault(key, mod)\n",
      "File \u001B[0;32m/tmp/torchinductor_alex/r2/cr2e7sfl7u7feurvzekeippm5knjnvjuhjtywsdyftctc4djhlhk.py:235\u001B[0m\n\u001B[1;32m    140\u001B[0m triton__4 \u001B[38;5;241m=\u001B[39m async_compile\u001B[38;5;241m.\u001B[39mtriton(\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;124mimport triton\u001B[39m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;124mimport triton.language as tl\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;124m    tl.atomic_add(out_ptr2 + (x0 + (4*tmp7) + tl.zeros([XBLOCK, 1], tl.int32)), tmp18, xmask)\u001B[39m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;124m'''\u001B[39m)\n\u001B[1;32m    196\u001B[0m triton__5 \u001B[38;5;241m=\u001B[39m async_compile\u001B[38;5;241m.\u001B[39mtriton(\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;124mimport triton\u001B[39m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;124mimport triton.language as tl\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;124m    tl.atomic_add(out_ptr1 + (x0 + (4*tmp15) + tl.zeros([XBLOCK], tl.int32)), tmp14, xmask)\u001B[39m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;124m'''\u001B[39m)\n\u001B[0;32m--> 235\u001B[0m \u001B[43masync_compile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m async_compile\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(args):\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/codecache.py:715\u001B[0m, in \u001B[0;36mAsyncCompile.wait\u001B[0;34m(self, scope)\u001B[0m\n\u001B[1;32m    713\u001B[0m             pbar\u001B[38;5;241m.\u001B[39mset_postfix_str(key)\n\u001B[1;32m    714\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, (Future, TritonFuture)):\n\u001B[0;32m--> 715\u001B[0m             scope[key] \u001B[38;5;241m=\u001B[39m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    716\u001B[0m             pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    718\u001B[0m _compile_end()\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/torch/_inductor/codecache.py:573\u001B[0m, in \u001B[0;36mTritonFuture.result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel\n\u001B[1;32m    572\u001B[0m \u001B[38;5;66;03m# If the worker failed this will throw an exception.\u001B[39;00m\n\u001B[0;32m--> 573\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    574\u001B[0m kernel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel \u001B[38;5;241m=\u001B[39m _load_kernel(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_code)\n\u001B[1;32m    575\u001B[0m latency \u001B[38;5;241m=\u001B[39m time() \u001B[38;5;241m-\u001B[39m t0\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/concurrent/futures/_base.py:458\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/concurrent/futures/_base.py:403\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mCompilationError\u001B[0m: at 34:12:\ndef triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n    xnumel = 20040\n    rnumel = 256\n    xoffset = tl.program_id(0) * XBLOCK\n    xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n    xmask = xindex < xnumel\n    rbase = tl.arange(0, RBLOCK)[None, :]\n    x1 = (xindex // 4)\n    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n    x0 = xindex % 4\n    tmp2 = tl.load(in_ptr2 + (x1), xmask)\n    _tmp5 = tl.zeros([XBLOCK, RBLOCK], tl.float32) + 0\n    x3 = xindex\n    tmp6 = tl.load(in_ptr4 + (x3), xmask)\n    tmp7 = tl.load(in_ptr5 + (x1), xmask)\n    for roffset in range(0, rnumel, RBLOCK):\n        rindex = roffset + rbase\n        rmask = rindex < rnumel\n        r2 = rindex\n        tmp1 = tl.load(in_ptr1 + (r2 + (256*x0) + (1024*tmp0)), rmask & xmask, eviction_policy='evict_last', other=0)\n        tmp3 = tl.load(in_ptr3 + (r2 + (256*x0) + (1024*tmp2)), rmask & xmask, eviction_policy='evict_last', other=0)\n        tmp4 = tmp1 * tmp3\n        _tmp5 = tl.where(rmask & xmask, _tmp5 + tmp4, _tmp5)\n        tmp8 = tl.load(in_ptr6 + (x0 + (4*tmp7)), xmask)\n        tmp9 = 1e-16\n        tmp10 = tmp8 + tmp9\n        tmp11 = tmp6 / tmp10\n        tmp12 = tmp1 * tmp11\n        tl.atomic_add(out_ptr1 + (r2 + (256*x0) + (1024*tmp2) + tl.zeros([XBLOCK, RBLOCK], tl.int32)), tmp12, rmask & xmask)\n    tmp5 = tl.sum(_tmp5, 1)[:, None]\n    tl.store(out_ptr0 + x3, tmp5, xmask)\n    tmp13 = -tmp5\n    tmp14 = 1e-16\n    tmp15 = tmp8 + tmp14\n            ^"
     ]
    }
   ],
   "source": [
    "from model.GraphBERT import ThroughputEstimator\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import lightning.pytorch as pl\n",
    "from model import GraphBERT\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "from torch_geometric import compile\n",
    "\n",
    "import importlib\n",
    "importlib.reload(GraphBERT)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n",
    "\n",
    "batch_size = 128\n",
    "hidden_dim = 256\n",
    "emb_size = 256\n",
    "\n",
    "num_training = int(0.7 * len(dataset))\n",
    "num_val = len(dataset) - num_training\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_training, num_val])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=6, drop_last=True)\n",
    "\n",
    "model = ThroughputEstimator(21000, emb_size, batch_size, hidden_dim)\n",
    "# model = compile(model)\n",
    "\n",
    "logger = TensorBoardLogger(\"runs\", name=\"bert\")\n",
    "logger.log_graph(model)\n",
    "trainer = pl.Trainer(max_epochs=40, logger=logger, callbacks=[ModelSummary(max_depth=-1)])\n",
    "trainer.fit(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T19:34:50.154610254Z",
     "start_time": "2023-09-10T19:34:21.659673110Z"
    }
   },
   "id": "3ed1dc75f632603"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T19:33:57.630623869Z",
     "start_time": "2023-09-10T19:33:57.626981158Z"
    }
   },
   "id": "bca183eaba292dd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
