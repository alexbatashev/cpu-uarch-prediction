{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T12:38:33.889629014Z",
     "start_time": "2023-11-06T12:38:33.846619404Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "class MCLatencyDecoder(Module):\n",
    "    def __init__(self, emb_size, nheads=4, dropout=0.1):\n",
    "        super(MCLatencyDecoder, self).__init__()\n",
    "        \n",
    "        self.attn1 = nn.MultiheadAttention(emb_size, num_heads=nheads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(emb_size)\n",
    "        self.attn2 = nn.MultiheadAttention(emb_size, num_heads=nheads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(emb_size)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(emb_size, emb_size * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_size * 4, emb_size)\n",
    "        )\n",
    "        \n",
    "        self.norm3 = nn.LayerNorm(emb_size)\n",
    "        \n",
    "    def forward(self, inp, encoded, mask=None):\n",
    "        # TODO figure out mask\n",
    "        x1, _ = self.attn1(inp, inp, inp, key_padding_mask=mask, need_weights=False)\n",
    "        x1 = self.norm1(x1 + inp)\n",
    "        \n",
    "        view = encoded[:, :x1.shape[1], :]\n",
    "        x2, _ = self.attn2(view, view, x1, key_padding_mask=mask, need_weights=False)\n",
    "        x2 = self.norm2(x2 + x1)\n",
    "        \n",
    "        x3 = self.feed_forward(x2)\n",
    "        x3 = self.norm3(x3 + x2)\n",
    "\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class MCNNConfig:\n",
    "    def __init__(self,\n",
    "                 num_opcodes,\n",
    "                 batch_size=64,\n",
    "                 embedding_size=128,\n",
    "                 hidden_size=256,\n",
    "                 num_heads_encoder=4,\n",
    "                 num_heads_decoder=4,\n",
    "                 num_encoders=4,\n",
    "                 num_decoders=4,\n",
    "                 dropout=0.1,\n",
    "                 learning_rate=1e-3,\n",
    "                 ):\n",
    "        self.num_opcodes = num_opcodes\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads_encoder = num_heads_encoder\n",
    "        self.num_heads_decoder = num_heads_decoder\n",
    "        self.num_encoders = num_encoders\n",
    "        self.num_decoders = num_decoders\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T11:56:29.630611938Z",
     "start_time": "2023-11-06T11:56:29.628325035Z"
    }
   },
   "id": "5b16471a22974bc1"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from llvm_ml.torch.nn import MCEmbedding, MCGraphEncoder\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "import math\n",
    "\n",
    "class MCLatencyTransformer(pl.LightningModule):\n",
    "    def __init__(self, config: MCNNConfig):\n",
    "        super(MCLatencyTransformer, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.embedding = MCEmbedding(self.config.num_opcodes, self.config.embedding_size)\n",
    "        self.encoders = nn.ModuleList(\n",
    "            [MCGraphEncoder(self.config.embedding_size, self.config.hidden_size, self.config.num_heads_encoder, self.config.dropout) for _ in range(self.config.num_encoders)]\n",
    "        )\n",
    "        \n",
    "        # TODO add positional encoding?\n",
    "        \n",
    "        self.decoders = nn.ModuleList(\n",
    "            [MCLatencyDecoder(self.config.embedding_size, self.config.num_heads_decoder, self.config.dropout) for _ in range(self.config.num_decoders)]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.config.embedding_size, self.config.embedding_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(self.config.embedding_size, self.config.embedding_size * 4),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(self.config.embedding_size * 4, self.config.embedding_size),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(self.config.embedding_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "        \n",
    "        \n",
    "    def forward(self, nodes, edge_index, batch):\n",
    "        embedded, pos_enc = self.embedding(nodes)\n",
    "        \n",
    "        encoded, mask = to_dense_batch(embedded, batch)\n",
    "        \n",
    "        dense_edges = to_dense_adj(edge_index, batch)\n",
    "        dense_edges = dense_edges.view(encoded.shape[0], encoded.shape[1], encoded.shape[1])\n",
    "        \n",
    "        for encoder in self.encoders:\n",
    "            encoded = encoder(encoded, dense_edges, mask)\n",
    "            \n",
    "        decoded_seq = torch.zeros((encoded.shape[0], encoded.shape[1], encoded.shape[2]), device=encoded.device, dtype=torch.float16)\n",
    "            \n",
    "        for i in range(1, encoded.shape[1]):\n",
    "            decoded = decoded_seq\n",
    "            for decoder in self.decoders:\n",
    "                decoded = decoder(decoded, encoded, torch.logical_not(mask))\n",
    "        \n",
    "            decoded = self.fc(decoded)\n",
    "            #decoded = self.softmax(decoded)\n",
    "                \n",
    "            #last_row = decoded[:, [-1], :]\n",
    "            #decoded_seq[:, [i - 1], :] = last_row\n",
    "            # decoded_seq = torch.cat((decoded_seq, last_row), dim=1)\n",
    "            decoded_seq = decoded\n",
    "            \n",
    "        #print(decoded_seq)\n",
    "        \n",
    "        out = self.regression(decoded_seq)\n",
    "        #print(decoded_seq)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "    def _step(self, batch, stage: str):\n",
    "        bb, raw, mask_id, original_token = batch\n",
    "\n",
    "        latencies = self.forward(bb.x, bb.edge_index, bb.batch)\n",
    "\n",
    "        latencies = torch.reshape(latencies, shape=(latencies.shape[0], latencies.shape[1]))\n",
    "        \n",
    "        y_hat = torch.sum(latencies[:, 1:], dim=1)\n",
    "        # print(y_hat)\n",
    "        \n",
    "        loss = F.mse_loss(y_hat, bb.y)\n",
    "        #print(latencies)\n",
    "\n",
    "        log_prefix = \"train\" if stage == 'train' else \"val\"\n",
    "\n",
    "        self.log(f\"{log_prefix}_loss\", loss, on_epoch=True, batch_size=self.config.batch_size)\n",
    "\n",
    "        return loss, bb, raw\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _, _ = self._step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _, _ = self._step(batch, 'val')\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.config.learning_rate, weight_decay=1e-3)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T12:38:40.412181737Z",
     "start_time": "2023-11-06T12:38:40.397275584Z"
    }
   },
   "id": "f8d474e757dfab6c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 347988 samples\n"
     ]
    }
   ],
   "source": [
    "from llvm_ml.torch import BasicBlockDataset\n",
    "banned_ids = []\n",
    "dataset = BasicBlockDataset(\"./data/ryzen3600_v16.cbuf\", masked=False, banned_ids=banned_ids, prefilter=True)\n",
    "print(f\"Training with {len(dataset)} samples\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T11:57:10.614858522Z",
     "start_time": "2023-11-06T11:56:29.647213707Z"
    }
   },
   "id": "ede0464077431d22"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "    | Name                             | Type                            | Params\n",
      "---------------------------------------------------------------------------------------\n",
      "0   | embedding                        | MCEmbedding                     | 1.3 M \n",
      "1   | embedding.embedding              | Embedding                       | 1.3 M \n",
      "2   | embedding.pos_encoding           | PositionalEncoding              | 0     \n",
      "3   | embedding.norm                   | LayerNorm                       | 128   \n",
      "4   | encoders                         | ModuleList                      | 198 K \n",
      "5   | encoders.0                       | MCGraphEncoder                  | 49.7 K\n",
      "6   | encoders.0.norm1                 | LayerNorm                       | 128   \n",
      "7   | encoders.0.attention             | MCGraphAttention                | 16.4 K\n",
      "8   | encoders.0.attention.heads       | MCAttentionHead                 | 16.4 K\n",
      "9   | encoders.0.attention.heads.key   | Linear                          | 4.1 K \n",
      "10  | encoders.0.attention.heads.query | Linear                          | 4.1 K \n",
      "11  | encoders.0.attention.heads.value | Linear                          | 4.1 K \n",
      "12  | encoders.0.attention.heads.proj  | Linear                          | 4.1 K \n",
      "13  | encoders.0.norm2                 | LayerNorm                       | 128   \n",
      "14  | encoders.0.feed_forward          | Sequential                      | 33.1 K\n",
      "15  | encoders.0.feed_forward.0        | Linear                          | 16.6 K\n",
      "16  | encoders.0.feed_forward.1        | GELU                            | 0     \n",
      "17  | encoders.0.feed_forward.2        | Linear                          | 16.4 K\n",
      "18  | encoders.0.feed_forward.3        | Dropout                         | 0     \n",
      "19  | encoders.1                       | MCGraphEncoder                  | 49.7 K\n",
      "20  | encoders.1.norm1                 | LayerNorm                       | 128   \n",
      "21  | encoders.1.attention             | MCGraphAttention                | 16.4 K\n",
      "22  | encoders.1.attention.heads       | MCAttentionHead                 | 16.4 K\n",
      "23  | encoders.1.attention.heads.key   | Linear                          | 4.1 K \n",
      "24  | encoders.1.attention.heads.query | Linear                          | 4.1 K \n",
      "25  | encoders.1.attention.heads.value | Linear                          | 4.1 K \n",
      "26  | encoders.1.attention.heads.proj  | Linear                          | 4.1 K \n",
      "27  | encoders.1.norm2                 | LayerNorm                       | 128   \n",
      "28  | encoders.1.feed_forward          | Sequential                      | 33.1 K\n",
      "29  | encoders.1.feed_forward.0        | Linear                          | 16.6 K\n",
      "30  | encoders.1.feed_forward.1        | GELU                            | 0     \n",
      "31  | encoders.1.feed_forward.2        | Linear                          | 16.4 K\n",
      "32  | encoders.1.feed_forward.3        | Dropout                         | 0     \n",
      "33  | encoders.2                       | MCGraphEncoder                  | 49.7 K\n",
      "34  | encoders.2.norm1                 | LayerNorm                       | 128   \n",
      "35  | encoders.2.attention             | MCGraphAttention                | 16.4 K\n",
      "36  | encoders.2.attention.heads       | MCAttentionHead                 | 16.4 K\n",
      "37  | encoders.2.attention.heads.key   | Linear                          | 4.1 K \n",
      "38  | encoders.2.attention.heads.query | Linear                          | 4.1 K \n",
      "39  | encoders.2.attention.heads.value | Linear                          | 4.1 K \n",
      "40  | encoders.2.attention.heads.proj  | Linear                          | 4.1 K \n",
      "41  | encoders.2.norm2                 | LayerNorm                       | 128   \n",
      "42  | encoders.2.feed_forward          | Sequential                      | 33.1 K\n",
      "43  | encoders.2.feed_forward.0        | Linear                          | 16.6 K\n",
      "44  | encoders.2.feed_forward.1        | GELU                            | 0     \n",
      "45  | encoders.2.feed_forward.2        | Linear                          | 16.4 K\n",
      "46  | encoders.2.feed_forward.3        | Dropout                         | 0     \n",
      "47  | encoders.3                       | MCGraphEncoder                  | 49.7 K\n",
      "48  | encoders.3.norm1                 | LayerNorm                       | 128   \n",
      "49  | encoders.3.attention             | MCGraphAttention                | 16.4 K\n",
      "50  | encoders.3.attention.heads       | MCAttentionHead                 | 16.4 K\n",
      "51  | encoders.3.attention.heads.key   | Linear                          | 4.1 K \n",
      "52  | encoders.3.attention.heads.query | Linear                          | 4.1 K \n",
      "53  | encoders.3.attention.heads.value | Linear                          | 4.1 K \n",
      "54  | encoders.3.attention.heads.proj  | Linear                          | 4.1 K \n",
      "55  | encoders.3.norm2                 | LayerNorm                       | 128   \n",
      "56  | encoders.3.feed_forward          | Sequential                      | 33.1 K\n",
      "57  | encoders.3.feed_forward.0        | Linear                          | 16.6 K\n",
      "58  | encoders.3.feed_forward.1        | GELU                            | 0     \n",
      "59  | encoders.3.feed_forward.2        | Linear                          | 16.4 K\n",
      "60  | encoders.3.feed_forward.3        | Dropout                         | 0     \n",
      "61  | decoders                         | ModuleList                      | 267 K \n",
      "62  | decoders.0                       | MCLatencyDecoder                | 66.8 K\n",
      "63  | decoders.0.attn1                 | MultiheadAttention              | 16.6 K\n",
      "64  | decoders.0.attn1.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "65  | decoders.0.norm1                 | LayerNorm                       | 128   \n",
      "66  | decoders.0.attn2                 | MultiheadAttention              | 16.6 K\n",
      "67  | decoders.0.attn2.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "68  | decoders.0.norm2                 | LayerNorm                       | 128   \n",
      "69  | decoders.0.feed_forward          | Sequential                      | 33.1 K\n",
      "70  | decoders.0.feed_forward.0        | Linear                          | 16.6 K\n",
      "71  | decoders.0.feed_forward.1        | GELU                            | 0     \n",
      "72  | decoders.0.feed_forward.2        | Linear                          | 16.4 K\n",
      "73  | decoders.0.norm3                 | LayerNorm                       | 128   \n",
      "74  | decoders.1                       | MCLatencyDecoder                | 66.8 K\n",
      "75  | decoders.1.attn1                 | MultiheadAttention              | 16.6 K\n",
      "76  | decoders.1.attn1.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "77  | decoders.1.norm1                 | LayerNorm                       | 128   \n",
      "78  | decoders.1.attn2                 | MultiheadAttention              | 16.6 K\n",
      "79  | decoders.1.attn2.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "80  | decoders.1.norm2                 | LayerNorm                       | 128   \n",
      "81  | decoders.1.feed_forward          | Sequential                      | 33.1 K\n",
      "82  | decoders.1.feed_forward.0        | Linear                          | 16.6 K\n",
      "83  | decoders.1.feed_forward.1        | GELU                            | 0     \n",
      "84  | decoders.1.feed_forward.2        | Linear                          | 16.4 K\n",
      "85  | decoders.1.norm3                 | LayerNorm                       | 128   \n",
      "86  | decoders.2                       | MCLatencyDecoder                | 66.8 K\n",
      "87  | decoders.2.attn1                 | MultiheadAttention              | 16.6 K\n",
      "88  | decoders.2.attn1.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "89  | decoders.2.norm1                 | LayerNorm                       | 128   \n",
      "90  | decoders.2.attn2                 | MultiheadAttention              | 16.6 K\n",
      "91  | decoders.2.attn2.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "92  | decoders.2.norm2                 | LayerNorm                       | 128   \n",
      "93  | decoders.2.feed_forward          | Sequential                      | 33.1 K\n",
      "94  | decoders.2.feed_forward.0        | Linear                          | 16.6 K\n",
      "95  | decoders.2.feed_forward.1        | GELU                            | 0     \n",
      "96  | decoders.2.feed_forward.2        | Linear                          | 16.4 K\n",
      "97  | decoders.2.norm3                 | LayerNorm                       | 128   \n",
      "98  | decoders.3                       | MCLatencyDecoder                | 66.8 K\n",
      "99  | decoders.3.attn1                 | MultiheadAttention              | 16.6 K\n",
      "100 | decoders.3.attn1.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "101 | decoders.3.norm1                 | LayerNorm                       | 128   \n",
      "102 | decoders.3.attn2                 | MultiheadAttention              | 16.6 K\n",
      "103 | decoders.3.attn2.out_proj        | NonDynamicallyQuantizableLinear | 4.2 K \n",
      "104 | decoders.3.norm2                 | LayerNorm                       | 128   \n",
      "105 | decoders.3.feed_forward          | Sequential                      | 33.1 K\n",
      "106 | decoders.3.feed_forward.0        | Linear                          | 16.6 K\n",
      "107 | decoders.3.feed_forward.1        | GELU                            | 0     \n",
      "108 | decoders.3.feed_forward.2        | Linear                          | 16.4 K\n",
      "109 | decoders.3.norm3                 | LayerNorm                       | 128   \n",
      "110 | fc                               | Linear                          | 4.2 K \n",
      "111 | softmax                          | Softmax                         | 0     \n",
      "112 | regression                       | Sequential                      | 33.2 K\n",
      "113 | regression.0                     | Linear                          | 16.6 K\n",
      "114 | regression.1                     | Linear                          | 16.4 K\n",
      "115 | regression.2                     | Linear                          | 65    \n",
      "---------------------------------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.390     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a7f73ce53bc441cb4dfe9ea4b8099a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cpu-uarch-prediction-py11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:268: You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d64dc77ae6134e9bbf7da3b488a82245"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ef21a93f84d48f986d47a7f04fd1aa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d26e6804d234fa9a27a235cdabed950"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27257d00a0224227a942149ba9bbdbe8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a9efd3b172c437d85ce0593de8109d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6013033abff14217a83633bb4e1c53cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "825cf46aae624866ab283573a6075673"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "640cd14414ed4666a4660ccabfab0d69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "249f5c56546d49818981af3549c37eef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e2d004d6f934059860d48d6deffaed1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b8cb9a9cc5a4a518de79df807763603"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32f8b8aa77dd4f7f9518adfa5725432e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86aa1b4e0945413fadb9af36d9850da6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd5efa346e97410eb0f52e25d43c84ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04d75536b56a4268b7772eb02be215ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6ee9b46a0c549988b9934b0322e3eda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b53817f20d244ff590a71b2d88d12c97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28a2bbc4964c4408a3c880095e753ae9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24960290184347c1b691cba9e3713a16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74b5afc21a75456185d8fa3c367bdd3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe1ae635bd3f42cdba524b8e9d3f0959"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbb5814d9f8344fd8274c4311db7d62b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f9bf12da5754407a85d5ccb7c1bdaef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cacad58a611469f9d7505a995936f47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ccbc05e4ce244dd981a711e6da20380"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ce4105a43784b4fb8f3e59c823b56e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83da3b77b86d41fd9dd5178a4b5daab6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0b65b856a9047a0864f41a873795631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b8a3d6473874107be0ba6140655318a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5227e960cffe4fa9b0bc12f05d265fa9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4857a6c1adb4df5af8acb7d58db7e96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d920bd894ee49fb88270317bda8bdcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "721ec492ff984fa6af91e85dd4c55a1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2901e0f48324fe7bd9b5159f8d45c61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ad2e5559a1a446cacd486302d4ddc06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a1dee8d81a44b579798b951d58c28d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13ccc7ffa90a4199a614f064dbf5c0ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9015d057d6844c9fb088c2a9f0a1dc65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da36a9afa539435186658509b8c107e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5ee383bb1bf46aea76e0f23ff7afb9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae51d272bfe24f50a9fe57661d8abb14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21cfe3d2d9ff421196f1f1c29996952d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ac0a83c8fd84f97863d832c8ba15c8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85c5941f47aa4b26bcafb08e996b90f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78618137c6584142be4e4ffa8f7c8c52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbce0c7909094d8784cb00344ea1ba38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ffe3ca9055a42aeb84f015211f9f847"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f0ffad18b184aacbe4bc62e24c2685e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "552074651cc34d78a286dd619db25f6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89faa19f9baf4137a30face4d152490d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a71c51e4824a4a96beb667c013473ffc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from lightning.pytorch.callbacks import ModelSummary, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n",
    "\n",
    "config = MCNNConfig(dataset.num_opcodes)\n",
    "config.learning_rate = 1e-5\n",
    "config.batch_size = 64\n",
    "config.hidden_size = 128\n",
    "config.embedding_size = 64\n",
    "\n",
    "num_training = int(0.7 * len(dataset))\n",
    "num_val = len(dataset) - num_training\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_training, num_val])\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=6, drop_last=True)\n",
    "\n",
    "model = MCLatencyTransformer(config)\n",
    "\n",
    "logger = TensorBoardLogger(\"runs\", name=\"transformer\")\n",
    "logger.log_graph(model)\n",
    "callbacks = [\n",
    "    ModelSummary(max_depth=-1),\n",
    "    LearningRateMonitor(),\n",
    "]\n",
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     logger=logger,\n",
    "                     precision='16-mixed',\n",
    "                     callbacks=callbacks,\n",
    "                     #fast_dev_run=True,\n",
    "                     overfit_batches=1,\n",
    "                     log_every_n_steps=1,\n",
    "                     )\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T12:41:44.730589186Z",
     "start_time": "2023-11-06T12:38:43.776545328Z"
    }
   },
   "id": "68d119ee7f3e8386"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T11:59:49.041297951Z",
     "start_time": "2023-11-06T11:59:49.033229762Z"
    }
   },
   "id": "2841ae818282d9d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
