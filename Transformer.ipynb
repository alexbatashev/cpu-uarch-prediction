{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T12:38:33.889629014Z",
     "start_time": "2023-11-06T12:38:33.846619404Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "class MCLatencyDecoder(Module):\n",
    "    def __init__(self, emb_size, nheads=4, dropout=0.1):\n",
    "        super(MCLatencyDecoder, self).__init__()\n",
    "        \n",
    "        self.attn1 = nn.MultiheadAttention(emb_size, num_heads=nheads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(emb_size)\n",
    "        self.attn2 = nn.MultiheadAttention(emb_size, num_heads=nheads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(emb_size)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(emb_size, emb_size * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_size * 4, emb_size)\n",
    "        )\n",
    "        \n",
    "        self.norm3 = nn.LayerNorm(emb_size)\n",
    "        \n",
    "    def forward(self, inp, encoded, mask=None):\n",
    "        # TODO figure out mask\n",
    "        x1, _ = self.attn1(inp, inp, inp, key_padding_mask=mask, need_weights=False)\n",
    "        x1 = self.norm1(x1 + inp)\n",
    "        \n",
    "        view = encoded[:, :x1.shape[1], :]\n",
    "        x2, _ = self.attn2(view, view, x1, key_padding_mask=mask, need_weights=False)\n",
    "        x2 = self.norm2(x2 + x1)\n",
    "        \n",
    "        x3 = self.feed_forward(x2)\n",
    "        x3 = self.norm3(x3 + x2)\n",
    "\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MCNNConfig:\n",
    "    def __init__(self,\n",
    "                 num_opcodes,\n",
    "                 batch_size=64,\n",
    "                 embedding_size=128,\n",
    "                 reg_forward_expansion=4,\n",
    "                 hidden_size=256,\n",
    "                 num_heads_encoder=4,\n",
    "                 num_heads_decoder=4,\n",
    "                 num_encoders=4,\n",
    "                 num_decoders=4,\n",
    "                 dropout=0.1,\n",
    "                 learning_rate=1e-3,\n",
    "                 ):\n",
    "        self.num_opcodes = num_opcodes\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads_encoder = num_heads_encoder\n",
    "        self.num_heads_decoder = num_heads_decoder\n",
    "        self.num_encoders = num_encoders\n",
    "        self.num_decoders = num_decoders\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_forward_expansion = reg_forward_expansion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T11:31:54.598499798Z",
     "start_time": "2023-11-11T11:31:54.593598397Z"
    }
   },
   "id": "5b16471a22974bc1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from llvm_ml.torch.nn import MCEmbedding, MCGraphEncoder\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "import math\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "\n",
    "class MCLatencyTransformer(pl.LightningModule):\n",
    "    def __init__(self, config: MCNNConfig):\n",
    "        super(MCLatencyTransformer, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.embedding = MCEmbedding(self.config.num_opcodes, self.config.embedding_size)\n",
    "        self.encoders = nn.ModuleList(\n",
    "            [MCGraphEncoder(self.config.embedding_size, self.config.hidden_size, self.config.num_heads_encoder, self.config.dropout) for _ in range(self.config.num_encoders)]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.config.embedding_size, self.config.embedding_size)\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(self.config.embedding_size, self.config.embedding_size * self.config.reg_forward_expansion),\n",
    "            nn.Linear(self.config.embedding_size * self.config.reg_forward_expansion, self.config.embedding_size * self.config.reg_forward_expansion),\n",
    "            nn.Linear(self.config.embedding_size * self.config.reg_forward_expansion, self.config.embedding_size * self.config.reg_forward_expansion // 2),\n",
    "            nn.Linear(self.config.embedding_size * self.config.reg_forward_expansion // 2, self.config.embedding_size),\n",
    "            nn.Linear(self.config.embedding_size, self.config.embedding_size // 2),\n",
    "            nn.Linear(self.config.embedding_size // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "        \n",
    "        \n",
    "    def forward(self, nodes, edge_index, batch):\n",
    "        embedded, pos_enc = self.embedding(nodes)\n",
    "        \n",
    "        encoded, mask = to_dense_batch(embedded, batch)\n",
    "        \n",
    "        dense_edges = to_dense_adj(edge_index, batch)\n",
    "        dense_edges = dense_edges.view(encoded.shape[0], encoded.shape[1], encoded.shape[1])\n",
    "        \n",
    "        for encoder in self.encoders:\n",
    "            encoded = encoder(encoded, dense_edges, mask)\n",
    "        \n",
    "        #encoded = encoded.masked_fill(mask == False, float(0))\n",
    "        encoded = self.fc(encoded)\n",
    "        \n",
    "        out = self.regression(encoded)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "    def _step(self, batch, stage: str):\n",
    "        bb, raw, mask_id, original_token = batch\n",
    "\n",
    "        latencies = self.forward(bb.x, bb.edge_index, bb.batch)\n",
    "\n",
    "        latencies = torch.reshape(latencies, shape=(latencies.shape[0], latencies.shape[1]))\n",
    "        \n",
    "        y_hat = torch.sum(latencies[:, 1:], dim=1)\n",
    "        # print(y_hat)\n",
    "        \n",
    "        loss = F.mse_loss(y_hat, bb.y)\n",
    "        #print(latencies)\n",
    "\n",
    "        log_prefix = \"train\" if stage == 'train' else \"val\"\n",
    "\n",
    "        self.log(f\"{log_prefix}_loss\", loss, on_epoch=True, batch_size=self.config.batch_size)\n",
    "\n",
    "        return loss, bb, raw\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _, _ = self._step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _, _ = self._step(batch, 'val')\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.config.learning_rate, weight_decay=1e-3)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T11:31:55.636631047Z",
     "start_time": "2023-11-11T11:31:55.617171683Z"
    }
   },
   "id": "f8d474e757dfab6c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 347988 samples\n"
     ]
    }
   ],
   "source": [
    "from llvm_ml.torch import BasicBlockDataset\n",
    "banned_ids = []\n",
    "dataset = BasicBlockDataset(\"./data/ryzen3600_v16.cbuf\", masked=False, banned_ids=banned_ids, prefilter=True)\n",
    "print(f\"Training with {len(dataset)} samples\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T11:32:33.891536884Z",
     "start_time": "2023-11-11T11:32:11.949272295Z"
    }
   },
   "id": "ede0464077431d22"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                             | Type               | Params\n",
      "-------------------------------------------------------------------------\n",
      "0  | embedding                        | MCEmbedding        | 5.4 M \n",
      "1  | embedding.embedding              | Embedding          | 5.4 M \n",
      "2  | embedding.pos_encoding           | PositionalEncoding | 0     \n",
      "3  | embedding.norm                   | LayerNorm          | 512   \n",
      "4  | encoders                         | ModuleList         | 3.2 M \n",
      "5  | encoders.0                       | MCGraphEncoder     | 788 K \n",
      "6  | encoders.0.norm1                 | LayerNorm          | 512   \n",
      "7  | encoders.0.attention             | MCGraphAttention   | 262 K \n",
      "8  | encoders.0.attention.heads       | MCAttentionHead    | 262 K \n",
      "9  | encoders.0.attention.heads.key   | Linear             | 65.5 K\n",
      "10 | encoders.0.attention.heads.query | Linear             | 65.5 K\n",
      "11 | encoders.0.attention.heads.value | Linear             | 65.5 K\n",
      "12 | encoders.0.attention.heads.proj  | Linear             | 65.5 K\n",
      "13 | encoders.0.norm2                 | LayerNorm          | 512   \n",
      "14 | encoders.0.feed_forward          | Sequential         | 525 K \n",
      "15 | encoders.0.feed_forward.0        | Linear             | 263 K \n",
      "16 | encoders.0.feed_forward.1        | GELU               | 0     \n",
      "17 | encoders.0.feed_forward.2        | Linear             | 262 K \n",
      "18 | encoders.0.feed_forward.3        | Dropout            | 0     \n",
      "19 | encoders.1                       | MCGraphEncoder     | 788 K \n",
      "20 | encoders.1.norm1                 | LayerNorm          | 512   \n",
      "21 | encoders.1.attention             | MCGraphAttention   | 262 K \n",
      "22 | encoders.1.attention.heads       | MCAttentionHead    | 262 K \n",
      "23 | encoders.1.attention.heads.key   | Linear             | 65.5 K\n",
      "24 | encoders.1.attention.heads.query | Linear             | 65.5 K\n",
      "25 | encoders.1.attention.heads.value | Linear             | 65.5 K\n",
      "26 | encoders.1.attention.heads.proj  | Linear             | 65.5 K\n",
      "27 | encoders.1.norm2                 | LayerNorm          | 512   \n",
      "28 | encoders.1.feed_forward          | Sequential         | 525 K \n",
      "29 | encoders.1.feed_forward.0        | Linear             | 263 K \n",
      "30 | encoders.1.feed_forward.1        | GELU               | 0     \n",
      "31 | encoders.1.feed_forward.2        | Linear             | 262 K \n",
      "32 | encoders.1.feed_forward.3        | Dropout            | 0     \n",
      "33 | encoders.2                       | MCGraphEncoder     | 788 K \n",
      "34 | encoders.2.norm1                 | LayerNorm          | 512   \n",
      "35 | encoders.2.attention             | MCGraphAttention   | 262 K \n",
      "36 | encoders.2.attention.heads       | MCAttentionHead    | 262 K \n",
      "37 | encoders.2.attention.heads.key   | Linear             | 65.5 K\n",
      "38 | encoders.2.attention.heads.query | Linear             | 65.5 K\n",
      "39 | encoders.2.attention.heads.value | Linear             | 65.5 K\n",
      "40 | encoders.2.attention.heads.proj  | Linear             | 65.5 K\n",
      "41 | encoders.2.norm2                 | LayerNorm          | 512   \n",
      "42 | encoders.2.feed_forward          | Sequential         | 525 K \n",
      "43 | encoders.2.feed_forward.0        | Linear             | 263 K \n",
      "44 | encoders.2.feed_forward.1        | GELU               | 0     \n",
      "45 | encoders.2.feed_forward.2        | Linear             | 262 K \n",
      "46 | encoders.2.feed_forward.3        | Dropout            | 0     \n",
      "47 | encoders.3                       | MCGraphEncoder     | 788 K \n",
      "48 | encoders.3.norm1                 | LayerNorm          | 512   \n",
      "49 | encoders.3.attention             | MCGraphAttention   | 262 K \n",
      "50 | encoders.3.attention.heads       | MCAttentionHead    | 262 K \n",
      "51 | encoders.3.attention.heads.key   | Linear             | 65.5 K\n",
      "52 | encoders.3.attention.heads.query | Linear             | 65.5 K\n",
      "53 | encoders.3.attention.heads.value | Linear             | 65.5 K\n",
      "54 | encoders.3.attention.heads.proj  | Linear             | 65.5 K\n",
      "55 | encoders.3.norm2                 | LayerNorm          | 512   \n",
      "56 | encoders.3.feed_forward          | Sequential         | 525 K \n",
      "57 | encoders.3.feed_forward.0        | Linear             | 263 K \n",
      "58 | encoders.3.feed_forward.1        | GELU               | 0     \n",
      "59 | encoders.3.feed_forward.2        | Linear             | 262 K \n",
      "60 | encoders.3.feed_forward.3        | Dropout            | 0     \n",
      "61 | fc                               | Linear             | 65.8 K\n",
      "62 | regression                       | Sequential         | 26.8 M\n",
      "63 | regression.0                     | Linear             | 1.1 M \n",
      "64 | regression.1                     | Linear             | 16.8 M\n",
      "65 | regression.2                     | Linear             | 8.4 M \n",
      "66 | regression.3                     | Linear             | 524 K \n",
      "67 | regression.4                     | Linear             | 32.9 K\n",
      "68 | regression.5                     | Linear             | 129   \n",
      "-------------------------------------------------------------------------\n",
      "35.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.4 M    Total params\n",
      "141.520   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dac425afafab477089e0a0ac318e969c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cpu-uarch-prediction-py11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:268: You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7b3b182a5fd4609bdfe7f51dab8bb75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13cc015fff4147c9abedbf3df7f89af2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07d7c169e44841f4b49ad3e2808cea92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65953d16770645fdb1f834117ea0acee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f80c3571b42c42f8a595f891a354a07f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "490fb0f5846d45ed843602abc134e55f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b54bb39a564e4e3490f491a97f94b74d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79a293e3c3c8459393def4f8f8ba9ee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad36a11cc0614d8c82d1eef5b5d5da18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88f811077d68488f8c3a77d3749ebb24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db426601a1ac4c5e986d45e272c43634"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7900df877934dc9a199698101267985"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "171a7655941a47e7ae7b070ad5703266"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c744609274a0470f9d3258cf2ca0eb0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "613e06da644649ae82670019c1f085f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60d2814697504f9183ed6a350011bd3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c32472ae79c7433ba8cf578f4cd0d7d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ae85e7b7f8643ae88460edb61439da3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7ea250fe4d348d8b91e9f040cc8aa39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efd075662a604b839ea7f9ad76691604"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b3941b40a494d4d9c775e516d533f24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e76ff221c10b4cffad1e1ff13a9d2292"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "929f30fed1534b67ac5829c5a0cb4410"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ef5996351fd49e38306ab0dc63a12df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83660eda5c3740b0a64ae25fb010f2e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a14a345bbfb348f6bf0fffd46ddae04b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from lightning.pytorch.callbacks import ModelSummary, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n",
    "\n",
    "config = MCNNConfig(dataset.num_opcodes)\n",
    "config.learning_rate = 2e-6\n",
    "config.batch_size = 256\n",
    "config.hidden_size = 128\n",
    "config.embedding_size = 256\n",
    "config.reg_forward_expansion = 16\n",
    "\n",
    "num_training = int(0.7 * len(dataset))\n",
    "num_val = len(dataset) - num_training\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_training, num_val])\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=6, drop_last=True)\n",
    "\n",
    "model = MCLatencyTransformer(config)\n",
    "\n",
    "logger = TensorBoardLogger(\"runs\", name=\"transformer\")\n",
    "logger.log_graph(model)\n",
    "callbacks = [\n",
    "    ModelSummary(max_depth=-1),\n",
    "    LearningRateMonitor(),\n",
    "]\n",
    "trainer = pl.Trainer(max_epochs=25,\n",
    "                     logger=logger,\n",
    "                     precision='16-mixed',\n",
    "                     callbacks=callbacks,\n",
    "                     #fast_dev_run=True,\n",
    "                     overfit_batches=1,\n",
    "                     log_every_n_steps=1,\n",
    "                     )\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T11:34:23.085931015Z",
     "start_time": "2023-11-11T11:33:47.896806105Z"
    }
   },
   "id": "68d119ee7f3e8386"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T11:59:49.041297951Z",
     "start_time": "2023-11-06T11:59:49.033229762Z"
    }
   },
   "id": "2841ae818282d9d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
