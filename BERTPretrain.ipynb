{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-19T12:19:15.246468575Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllvm_ml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BasicBlockDataset\n\u001B[1;32m      2\u001B[0m banned_ids \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 3\u001B[0m dataset \u001B[38;5;241m=\u001B[39m BasicBlockDataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/ryzen3600_v16.cbuf\u001B[39m\u001B[38;5;124m\"\u001B[39m, masked\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, banned_ids\u001B[38;5;241m=\u001B[39mbanned_ids, prefilter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining with \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mlen(dataset)} samples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/cpu-uarch-prediction-py11/lib/python3.11/site-packages/llvm_ml/torch/dataset.py:10\u001B[0m, in \u001B[0;36mBasicBlockDataset.__init__\u001B[0;34m(self, dataset_path, step, prefilter, masked, banned_ids)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_path, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.05\u001B[39m\u001B[38;5;124m\"\u001B[39m, prefilter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, masked\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, banned_ids\u001B[38;5;241m=\u001B[39m[]):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m---> 10\u001B[0m     basic_blocks \u001B[38;5;241m=\u001B[39m load_pytorch_dataset(dataset_path, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_opcodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m21000\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask_opcode \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m21001\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from llvm_ml.torch import BasicBlockDataset\n",
    "banned_ids = []\n",
    "dataset = BasicBlockDataset(\"./data/ryzen3600_v16.cbuf\", masked=True, banned_ids=banned_ids, prefilter=True)\n",
    "print(f\"Training with {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                       | Type               | Params\n",
      "-------------------------------------------------------------------\n",
      "0  | embedding                  | MCEmbedding        | 5.4 M \n",
      "1  | embedding.embedding        | Embedding          | 5.4 M \n",
      "2  | embedding.pos_encoding     | PositionalEncoding | 0     \n",
      "3  | embedding.norm             | LayerNorm          | 512   \n",
      "4  | encoders                   | ModuleList         | 2.1 M \n",
      "5  | encoders.0                 | MCGraphEncoder     | 526 K \n",
      "6  | encoders.0.norm1           | LayerNorm          | 512   \n",
      "7  | encoders.0.attention       | MCGraphAttention   | 262 K \n",
      "8  | encoders.0.attention.key   | Linear             | 65.5 K\n",
      "9  | encoders.0.attention.query | Linear             | 65.5 K\n",
      "10 | encoders.0.attention.value | Linear             | 65.5 K\n",
      "11 | encoders.0.attention.proj  | Linear             | 65.5 K\n",
      "12 | encoders.0.norm2           | LayerNorm          | 512   \n",
      "13 | encoders.0.feed_forward    | Sequential         | 262 K \n",
      "14 | encoders.0.feed_forward.0  | Linear             | 131 K \n",
      "15 | encoders.0.feed_forward.1  | GELU               | 0     \n",
      "16 | encoders.0.feed_forward.2  | Linear             | 131 K \n",
      "17 | encoders.0.feed_forward.3  | Dropout            | 0     \n",
      "18 | encoders.1                 | MCGraphEncoder     | 526 K \n",
      "19 | encoders.1.norm1           | LayerNorm          | 512   \n",
      "20 | encoders.1.attention       | MCGraphAttention   | 262 K \n",
      "21 | encoders.1.attention.key   | Linear             | 65.5 K\n",
      "22 | encoders.1.attention.query | Linear             | 65.5 K\n",
      "23 | encoders.1.attention.value | Linear             | 65.5 K\n",
      "24 | encoders.1.attention.proj  | Linear             | 65.5 K\n",
      "25 | encoders.1.norm2           | LayerNorm          | 512   \n",
      "26 | encoders.1.feed_forward    | Sequential         | 262 K \n",
      "27 | encoders.1.feed_forward.0  | Linear             | 131 K \n",
      "28 | encoders.1.feed_forward.1  | GELU               | 0     \n",
      "29 | encoders.1.feed_forward.2  | Linear             | 131 K \n",
      "30 | encoders.1.feed_forward.3  | Dropout            | 0     \n",
      "31 | encoders.2                 | MCGraphEncoder     | 526 K \n",
      "32 | encoders.2.norm1           | LayerNorm          | 512   \n",
      "33 | encoders.2.attention       | MCGraphAttention   | 262 K \n",
      "34 | encoders.2.attention.key   | Linear             | 65.5 K\n",
      "35 | encoders.2.attention.query | Linear             | 65.5 K\n",
      "36 | encoders.2.attention.value | Linear             | 65.5 K\n",
      "37 | encoders.2.attention.proj  | Linear             | 65.5 K\n",
      "38 | encoders.2.norm2           | LayerNorm          | 512   \n",
      "39 | encoders.2.feed_forward    | Sequential         | 262 K \n",
      "40 | encoders.2.feed_forward.0  | Linear             | 131 K \n",
      "41 | encoders.2.feed_forward.1  | GELU               | 0     \n",
      "42 | encoders.2.feed_forward.2  | Linear             | 131 K \n",
      "43 | encoders.2.feed_forward.3  | Dropout            | 0     \n",
      "44 | encoders.3                 | MCGraphEncoder     | 526 K \n",
      "45 | encoders.3.norm1           | LayerNorm          | 512   \n",
      "46 | encoders.3.attention       | MCGraphAttention   | 262 K \n",
      "47 | encoders.3.attention.key   | Linear             | 65.5 K\n",
      "48 | encoders.3.attention.query | Linear             | 65.5 K\n",
      "49 | encoders.3.attention.value | Linear             | 65.5 K\n",
      "50 | encoders.3.attention.proj  | Linear             | 65.5 K\n",
      "51 | encoders.3.norm2           | LayerNorm          | 512   \n",
      "52 | encoders.3.feed_forward    | Sequential         | 262 K \n",
      "53 | encoders.3.feed_forward.0  | Linear             | 131 K \n",
      "54 | encoders.3.feed_forward.1  | GELU               | 0     \n",
      "55 | encoders.3.feed_forward.2  | Linear             | 131 K \n",
      "56 | encoders.3.feed_forward.3  | Dropout            | 0     \n",
      "57 | token_prediction           | Linear             | 5.4 M \n",
      "-------------------------------------------------------------------\n",
      "12.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.9 M    Total params\n",
      "51.515    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72a7646bdd0c45c3875450c7aef32bc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bfe8bb6bd8b4a149acc21f316e94ffc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3b5eb8ba76a43b095336a68d25c3db2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7341e621be24461bf17ea27009ec845"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57baf14dec344bedaf053db4b2c602d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23193759b82b40e3ab914eaee63801af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "161045a53a2547d6bb5a18a10638343a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a17793ab92ee4d469652cb19c0e8c068"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51db276286374540b2722bb8b4e2e64c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a33e042a99c4847859024873f643a16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cpu-uarch-prediction-py11/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from llvm_ml.torch.nn import MCBERT, MCNNConfig\n",
    "from torch_geometric.loader import DataLoader\n",
    "from lightning.pytorch.callbacks import ModelSummary, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n",
    "\n",
    "config = MCNNConfig(dataset.num_opcodes)\n",
    "config.learning_rate = 3e-5\n",
    "config.batch_size = 256\n",
    "config.hidden_size = 128\n",
    "config.embedding_size = 256\n",
    "# config.reg_forward_expansion = 16\n",
    "config.forward_expansion = 2\n",
    "\n",
    "num_training = int(0.7 * len(dataset))\n",
    "num_val = len(dataset) - num_training\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_training, num_val])\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=6, drop_last=True)\n",
    "\n",
    "model = MCBERT(config)\n",
    "\n",
    "logger = TensorBoardLogger(\"runs\", name=\"bert_pretrain\")\n",
    "logger.log_graph(model)\n",
    "callbacks = [\n",
    "    ModelSummary(max_depth=-1),\n",
    "    LearningRateMonitor(),\n",
    "]\n",
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     logger=logger,\n",
    "                     precision='16-mixed',\n",
    "                     callbacks=callbacks,\n",
    "                     #fast_dev_run=True,\n",
    "                     #overfit_batches=1,\n",
    "                     #log_every_n_steps=1,\n",
    "                     )\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T09:17:50.127615948Z",
     "start_time": "2023-11-19T09:00:47.387492343Z"
    }
   },
   "id": "4571129ca71ccf07"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "torch.save(model, \"data/bert_ryzen3600.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T09:17:54.259554845Z",
     "start_time": "2023-11-19T09:17:54.141851773Z"
    }
   },
   "id": "fc95ff5d0124624c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c0c6085911707623"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
