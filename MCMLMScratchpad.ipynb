{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-27T06:51:17.178491277Z",
     "start_time": "2023-08-27T06:51:15.832702317Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric as tg\n",
    "from llvm_ml.utils import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class MCMLMDataset(tg.data.Dataset):\n",
    "    def __init__(self, path, context_length=2):\n",
    "        super().__init__()\n",
    "        dataset = load_dataset(path, True, False)\n",
    "        \n",
    "        self.context_length = 2\n",
    "        \n",
    "        self.graphs = []\n",
    "        self.masked_ids = []\n",
    "        \n",
    "        for piece in dataset:\n",
    "            if len(piece.nodes) < (context_length * 2 + 1):\n",
    "                continue\n",
    "\n",
    "            nodes = np.zeros(len(piece.nodes), dtype=np.int_)\n",
    "            \n",
    "            for idx, n in enumerate(piece.nodes):\n",
    "                nodes[idx] = n.opcode\n",
    "\n",
    "            edges = np.zeros((len(piece.edges), 2), dtype=np.int_)\n",
    "\n",
    "            for idx, e in enumerate(piece.edges):\n",
    "                edges[idx, 0] = e.from_node\n",
    "                edges[idx, 1] = e.to_node\n",
    "\n",
    "            for idx in range(context_length, len(piece.nodes) - context_length):\n",
    "                self.masked_ids.append(idx)\n",
    "                self.graphs.append(tg.data.Data(x=torch.from_numpy(nodes), edge_index=torch.from_numpy(np.transpose(edges)).contiguous(), y=torch.tensor(piece.nodes[idx].opcode)))\n",
    "\n",
    "    def len(self) -> int:\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx: int):\n",
    "        return self.graphs[idx], self.masked_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 728026 examples\n"
     ]
    }
   ],
   "source": [
    "dataset = MCMLMDataset(\"./data/ryzen3600_v8.cbuf\")\n",
    "print(f\"Training with {len(dataset)} examples\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T06:53:14.410307491Z",
     "start_time": "2023-08-27T06:51:23.749028944Z"
    }
   },
   "id": "d329ca50c5408117"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.nn import Embedding, Linear\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class MCMLM(pl.LightningModule):\n",
    "    def __init__(self, hidden_size, num_opcodes, batch_size, embedding_dim=32, context_size=2, learning_rate=0.002):\n",
    "        super(MCMLM, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.context_size = context_size\n",
    "        self.num_opcodes = num_opcodes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.embedding = Embedding(num_embeddings=num_opcodes, embedding_dim=embedding_dim)\n",
    "        self.conv = GraphConv(embedding_dim, hidden_size)\n",
    "        \n",
    "        self.fc = Linear(hidden_size, hidden_size)\n",
    "        self.decode = Linear(hidden_size, num_opcodes)\n",
    "\n",
    "        self.val_accuracy = Accuracy(task=\"binary\")\n",
    "        self.train_accuracy = Accuracy(task=\"binary\")\n",
    "        \n",
    "        \n",
    "    def forward(self, data, masked_id):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = self.conv(x, edge_index)\n",
    "        nodes, _ = to_dense_batch(x, batch)\n",
    "\n",
    "        x = torch.zeros(self.batch_size, self.context_size * 2 + 1, nodes.shape[2], device=x.device, dtype=x.dtype)\n",
    "        \n",
    "        for b in range(self.batch_size):\n",
    "            for idx, val in enumerate(range(-self.context_size, self.context_size + 1)):\n",
    "                if val == 0:\n",
    "                    x[b, idx, :] = 0\n",
    "                else:\n",
    "                    x[b, idx, :] = nodes[b, masked_id[b] + val, :]\n",
    "        \n",
    "        x = F.gelu(x)\n",
    "        x = self.fc(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.decode(x)\n",
    "        x = x[:, self.context_size, :]\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        x = x.reshape(self.batch_size, self.num_opcodes)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, masked_ids = batch\n",
    "        \n",
    "        y_hat = self(data, masked_ids)\n",
    "        \n",
    "        target = torch.zeros(self.batch_size, self.num_opcodes, dtype=y_hat.dtype)\n",
    "        for idx in masked_ids:\n",
    "            target[:, idx] = 1\n",
    "\n",
    "        target = target.to(y_hat.device)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(y_hat, target)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, batch_size=self.batch_size)\n",
    "        self.train_accuracy(y_hat, target)\n",
    "        self.log(\"train_accuracy\", self.train_accuracy)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, masked_ids = batch\n",
    "\n",
    "        y_hat = self(data, masked_ids)\n",
    "\n",
    "        target = torch.zeros(self.batch_size, self.num_opcodes, dtype=y_hat.dtype)\n",
    "        for idx in masked_ids:\n",
    "            target[:, idx] = 1\n",
    "\n",
    "        target = target.to(y_hat.device)\n",
    "        loss = F.binary_cross_entropy(y_hat, target)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, batch_size=self.batch_size)\n",
    "        self.val_accuracy(y_hat, target)\n",
    "        self.log(\"val_accuracy\", self.val_accuracy, on_epoch=True, batch_size=self.batch_size)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5, verbose=True, min_lr=1e-6, cooldown=5)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T06:53:15.103704711Z",
     "start_time": "2023-08-27T06:53:14.410040222Z"
    }
   },
   "id": "b048b91f8711227c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-08-27 09:53:16.015845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-27 09:53:16.525056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type           | Params\n",
      "--------------------------------------------------\n",
      "0 | embedding      | Embedding      | 672 K \n",
      "1 | conv           | GraphConv      | 8.3 K \n",
      "2 | fc             | Linear         | 16.5 K\n",
      "3 | decode         | Linear         | 2.7 M \n",
      "4 | val_accuracy   | BinaryAccuracy | 0     \n",
      "5 | train_accuracy | BinaryAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "3.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 M     Total params\n",
      "13.623    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91c7bc7596b64395981e614700810696"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a6b246fdc594e83bfe7a8f7d0ad465e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/cpu-uarch-prediction/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import torch.utils.data\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "batch_size = 512\n",
    "hidden_size = 128\n",
    "\n",
    "num_training = int(0.7 * len(dataset))\n",
    "num_val = len(dataset) - num_training\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_training, num_val])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=6, drop_last=True)\n",
    "\n",
    "model = MCMLM(hidden_size, 21000, batch_size)\n",
    "\n",
    "logger = TensorBoardLogger(\"runs\", name=\"mcmlm\")\n",
    "logger.log_graph(model)\n",
    "trainer = pl.Trainer(max_epochs=100, logger=logger, fast_dev_run=False)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:06:42.089473557Z",
     "start_time": "2023-08-27T06:53:15.107189011Z"
    }
   },
   "id": "55e01d238198ec30"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:06:42.101461656Z",
     "start_time": "2023-08-27T07:06:42.099234605Z"
    }
   },
   "id": "487a99ab94ba31b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
